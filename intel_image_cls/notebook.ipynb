{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import wandb\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "PRJ_NAME = 'intel_image_cls'\n",
    "kls = [\n",
    "    \"buildings\",\n",
    "    \"forest\",\n",
    "    \"glacier\",\n",
    "    \"mountain\",\n",
    "    \"sea\",\n",
    "    \"street\"\n",
    "]\n",
    "\n",
    "\n",
    "def accuracy(y_hat: torch.Tensor, y: torch.Tensor):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    return float((y_hat.type(y.dtype) == y).sum())\n",
    "\n",
    "\n",
    "def train_epoch(net, train_data, loss, updater, device):\n",
    "    net.train()\n",
    "    acc_sum, lsum, numel = 0, 0, 0\n",
    "    for X, y in tqdm(train_data):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        updater.zero_grad()\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        l.mean().backward()\n",
    "        updater.step()\n",
    "        lsum += l.sum().detach()\n",
    "        numel += y.numel()\n",
    "        acc_sum += accuracy(y_hat, y)\n",
    "\n",
    "    return (lsum / numel), (acc_sum / numel)\n",
    "\n",
    "def init_weight(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        print(f'initialize weight : {m}')\n",
    "\n",
    "def train(net: nn.Module, train_data, val_data, device, config):\n",
    "    with wandb.init(project=PRJ_NAME, job_type='training') as run:\n",
    "        lr, num_epochs = config['lr'], config['epochs']\n",
    "        net = net.to(device)\n",
    "        net.apply(init_weight)\n",
    "        print(f'network : {net.__class__.__name__}')\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "        loss = loss.to(device)\n",
    "        for epoch in range(num_epochs):\n",
    "            tloss, tacc = train_epoch(net, train_data, loss, updater, device)\n",
    "            val_loss, val_acc = evaluate(net, val_data, loss, device)\n",
    "            metric = {\n",
    "                'train_loss': tloss,\n",
    "                'train_accuracy': tacc,\n",
    "                'validation_loss': val_loss,\n",
    "                'validation_accuracy': val_acc\n",
    "            }\n",
    "            wandb.log(metric)\n",
    "            print(f'Ep {epoch} : {metric}')\n",
    "\n",
    "        torch.save(net.state_dict(), f'{net.__class__.__name__}.pt')\n",
    "        trained_model = wandb.Artifact(f'{net.__class__.__name__}', type='model', description=f'{str(net)}')\n",
    "        trained_model.add_file(f'{net.__class__.__name__}.pt')\n",
    "        run.log_artifact(trained_model)\n",
    "\n",
    "    \n",
    "def evaluate(net, val_data, loss, device):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        acc_sum, lsum, numel = 0, 0, 0\n",
    "        for X, y in val_data:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            lsum += loss(y_hat, y).sum()\n",
    "            acc_sum += accuracy(y_hat, y)\n",
    "            numel += y.numel()\n",
    "    return (lsum / numel), (acc_sum / numel)\n",
    "\n",
    "\n",
    "def try_gpu():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL.Image import Image\n",
    "\n",
    "class Padding(object):\n",
    "    \n",
    "    def __init__(self, size: Tuple):\n",
    "        super(Padding).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, X: Image):\n",
    "        ## torch compatible image fromat assumed (N,C,H,W)\n",
    "        h, w = self.size\n",
    "        iw, ih = X.size\n",
    "        if ih == h and iw == w:\n",
    "            return X\n",
    "        else:\n",
    "            tp = (h - ih) // 2\n",
    "            bp = h - tp - ih\n",
    "            lp = (w - iw) // 2\n",
    "            rp = w - lp - iw\n",
    "            return F.pad(X, [lp, tp, rp, bp])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "> Mainly based on idea of Inception block from googLeNet while adopting the concept of DenseNet, which has showed better resilience vanishing gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple network test\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, output_channels, kernels=[3, 5]):\n",
    "        super().__init__()\n",
    "        self.kerenls = kernels\n",
    "        for idx, k in enumerate(kernels):\n",
    "            if k % 2 == 0:\n",
    "                raise 'kernel size should be odd number'\n",
    "            self._modules[f'Conv Ch.{idx}_K_{k}X{k}'] = nn.Conv2d(input_channels, output_channels, kernel_size=k, padding=(k // 2))\n",
    "        self._modules[f'MxPool_Kx3'] = nn.Sequential(\n",
    "            nn.MaxPool2d(3, padding=1, stride=1), \n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=1))\n",
    "        self._modules[f'Conv1X1'] = nn.Conv2d(input_channels, output_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Y = []\n",
    "        for idx, k in enumerate(self.kerenls):\n",
    "            Y.append(self._modules[f'Conv Ch.{idx}_K_{k}X{k}'](X))\n",
    "        Y.append(self._modules[f'MxPool_Kx3'](X))\n",
    "        Y.append(self._modules[f'Conv1X1'](X))\n",
    "        Y.append(X)\n",
    "        return torch.cat(Y,axis=1)\n",
    "            \n",
    "\n",
    "class DenseInception_V0(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__(InceptionBlock(3, 8),\n",
    "            nn.BatchNorm2d(8 * 4 + 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       ## (n, 35, 75,75)\n",
    "            nn.Conv2d(8 * 4 + 3, 8 * 2, kernel_size=1),  ## (n, 16, 75, 75)\n",
    "            InceptionBlock(8 * 2, 8 * 2),                ## (n, 80, 75, 75)  \n",
    "            nn.BatchNorm2d(8 * 2 * 5),                       \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3),       ## (n, 80, 25, 25)\n",
    "            nn.Conv2d(8 * 2 * 5, 8 * 5, kernel_size=1),  ## (n, 40, 25, 25)\n",
    "            InceptionBlock(8 * 5, 8 * 5),                ## (n, 200, 25, 25)\n",
    "            nn.BatchNorm2d(8 * 5 * 5),                   \n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1),      ## (n, 200, 9, 9)\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 5 * 5 * 9 * 9, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, len(kls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "from torch import nn\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "from torch.utils import data\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "INPUT_DATA_BASE = '/kaggle/input/intel-image-classification/'\n",
    "project_name = 'intel_image_cls'\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "wandb_api = user_secrets.get_secret(\"wandb\")\n",
    "\n",
    "wandb.login(key=wandb_api)\n",
    "wandb.init(project=project_name, entity=\"dwidlee\")\n",
    "\n",
    "lr, epochs, batch = 0.001, 10, 8\n",
    "\n",
    "def run_train():\n",
    "    with wandb.init(project=PRJ_NAME, job_type='training') as run:\n",
    "        device = try_gpu()\n",
    "        config = wandb.config\n",
    "        print(config)\n",
    "\n",
    "        train_preprocess = torch.jit.script_if_tracing(T.Compose([\n",
    "            Padding((150, 150)),\n",
    "            T.RandomAffine(degrees=(-10,10), translate=(0.1, 0.1), scale=(0.9,1.1)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor()\n",
    "        ]))\n",
    "\n",
    "        val_preprocess = torch.jit.script_if_tracing(T.Compose([\n",
    "            Padding((150, 150)),\n",
    "            T.ToTensor()\n",
    "        ]))\n",
    "\n",
    "        validate_set = datasets.ImageFolder(root='data/seg_test', transform=val_preprocess)\n",
    "        train_set = datasets.ImageFolder(root='data/seg_train', transform=train_preprocess)\n",
    "        train_data = data.DataLoader(train_set, batch_size=config['batch'], shuffle=True, num_workers=5)\n",
    "        val_data = data.DataLoader(validate_set, batch_size=config['batch'], shuffle=True, num_workers=5)\n",
    "        net = DenseInception_V0()\n",
    "        train(net, train_data, val_data, device, config)\n",
    "        torch.save(net.state_dict(), f'{net.__class__.__name__}.pt')\n",
    "        trained_model = wandb.Artifact(f'{net.__class__.__name__}', type='model', description=f'{str(net)}')\n",
    "        trained_model.add_file(f'{net.__class__.__name__}.pt')\n",
    "        run.log_artifact(trained_model)\n",
    "\n",
    "\n",
    "sweep_id = '3gfg64vc'\n",
    "count = 5\n",
    "wandb.agent(sweep_id, project=project_name, function=run_train, count=count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
